---
title: "Understanding Apartment Evaluation in Toronto"
subtitle: "Age, Size, and Location Influenced Score with Property Standards"
author: 
  - Yiyi Yao
thanks: "Code and data are available at: [https://github.com/Yaoee111/condo_evaluation]."
date: 03 December, 2024
date-format: long
abstract: "This paper analyzes building evaluation scores from Toronto's RentSafeTO program to understand the factors influencing compliance with property standards. Using a Bayesian regression model, we examined the relationships between building characteristics such as year built, number of units, and geographic location. We found that newer buildings, larger properties, and those in specific wards are more likely to achieve higher evaluation scores, reflecting better maintenance and compliance. These findings highlight the importance of modern construction, economies of scale in property management, and localized enforcement practices in ensuring housing quality, offering insights to policymakers and property managers striving to improve urban housing standards."
format: pdf
toc: true
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(knitr)
library(rstanarm)
library(sjPlot)
library(ggplot2)
library(patchwork)
library(ggdist)
```

```{r}
#| include: false
#| warning: false
#| message: false

data <- read.csv("/cloud/project/data/02-analysis_data/toronto_apartment_evaluation.csv")
```


# Introduction

Ensuring the quality and safety of rental housing is a critical issue in urban areas, especially as cities like Toronto face growing populations and aging infrastructure. The RentSafeTO program, launched in 2017, is a bylaw enforcement initiative designed to maintain property standards for multi-unit residential buildings. This program assesses compliance with maintenance standards, focusing on elements such as building exteriors, mechanical systems, and common areas. While the program provides a structured approach to evaluating building conditions, understanding the factors that influence these evaluation scores remains crucial for improving housing standards and targeting interventions effectively.

This paper investigates the key determinants of building evaluation scores in Toronto, using data from the RentSafeTO program. Specifically, we examine how building characteristics—such as the year of construction, number of units, and geographic location (ward)—affect compliance with property standards. Despite the availability of detailed evaluation data, limited research has explored the underlying factors that contribute to variations in scores across buildings and neighborhoods. This gap is significant, as understanding these relationships can inform policy decisions and enhance the effectiveness of programs like RentSafeTO.

To address this gap, we applied a Bayesian linear regression model to analyze the relationships between building characteristics and evaluation scores. This model accounts for ward-level variability through random effects, capturing local factors that may influence compliance. The findings reveal that newer buildings and larger properties generally achieve higher evaluation scores, likely due to modern construction practices and economies of scale in property management. Additionally, geographic location plays a significant role, with some wards showing consistently higher or lower scores, reflecting neighborhood-specific dynamics.

These results are important because they provide actionable insights for policymakers and property managers. By identifying the factors that influence compliance, this research highlights opportunities to prioritize maintenance efforts, target policy interventions, and improve the consistency of property evaluations. Ultimately, understanding these dynamics can contribute to better housing conditions and more equitable enforcement of property standards across Toronto.

The remainder of this paper is organized into distinct sections. @sec-data provides an overview of the dataset used in our analysis, including tables and graphs to illustrate the characteristics of buildings and evaluation scores. @sec-model outlines the Bayesian model employed, explaining its formulation and justification. @sec-result presents the findings, using tables and visualizations to highlight the relationships between building characteristics and evaluation scores. Finally, @sec-discussion offers a detailed discussion of the results, focusing on how factors such as construction year, building size, and geographic location influence compliance with property standards. 

## Estimand

The estimand in this paper is the evaluation score of apartment buildings as a measure of their compliance with property standards under the RentSafeTO program. However, it is challenging to assess the exact evaluation scores for all apartment buildings in Toronto, as not all buildings are included in the RentSafeTO dataset. For instance, smaller buildings or those outside the program's jurisdiction are excluded, limiting the scope of evaluation. Additionally, variability in inspections and data gaps may impact the accuracy of the scores. Therefore, in this paper, we estimate the estimand using a Bayesian linear regression model fitted with a subset of the RentSafeTO dataset.




# Data {#sec-data}

We use the statistical programming language R [@citeR] with packages `tidyverse` [@citeTidyverse], , `rstanarm` [@rstanarm], `knitr` [@citeKnitr], `tidybayes` [@tidybayes], `ggplot2` [@citeggplot2], `sjPlot` [@citesjPlot], `patchwork` [@citepatchwork], `ggdist` [@citeggdist], and follow @tellingstories.

## Data source

Data for this research comes from RentSafeTO program provided by Open Data Toronto (@opendata). This dataset contains building evaluation scores for apartment buildings registered with the RentSafeTO program in Toronto until 2023. RentSafeTO (@rentsafeto_tool), established in 2017, is a bylaw enforcement initiative designed to ensure that apartment buildings with three or more storeys or at least 10 units meet required maintenance standards. Alongside evaluation details, the dataset provides information about the buildings, including their address, year built, and geographical coordinates. The RentSafeTO dataset was selected because it provides a comprehensive overview of apartment building maintenance standards in Toronto.

## Data Features

The original RentSafeTo dataset, which shows in Appendix @sec-data-details, contains 3573 data entries and many variables. Since we only interested in data in downtown Toronto, this report will only explore and analyze through several data features. We chose these 8 variables: RSN, WARD, WARDNAME, YEAR.BUILT, PROPERTY.TYPE, CONFIRMED.STOREYS, CONFIRMED.UNITS, CURRENT.BUILDING.EVAL.SCORE. Details of these selected variables are also in @sec-data-details. We could use such features to predict building condition in downtown Toronto.

## Data Measurement

The data in this dataset was collected by bylaw enforcement officers as part of the RentSafeTO program. These inspections evaluate building maintenance standards across various categories, such as exterior grounds, mechanical systems, and common areas. Scores are assigned on a scale of 1 to 3, with 1 being the lowest and 3 being the highest. A score of 0 is given when an item cannot be evaluated due to obstruction or refusal, and blanks are recorded when an item is not applicable.

The unit of measurement for most numerical data is an ordinal score (1 to 3). Other features, such as building types or ward names, are categorical with no specific units.

## Data limitation

The data represents evaluations of buildings registered under RentSafeTO, so it does not cover all apartment buildings in Toronto. This limits its ability to represent the full state of rental housing in the city. Additionally, the evaluation process can be affected by variability in inspector judgments, leading to potential inconsistencies in scores. Gaps in the data, such as 0 scores or blanks, further complicate analysis and reduce the dataset's completeness. Moreover, the dataset primarily focuses on physical and structural conditions, neglecting tenant perspectives or broader social factors that may influence overall building quality. These limitations highlight the need to interpret the data with caution when making broader inferences.

## Data Methodology

The original dataset contains information on all registered apartment buildings in the Toronto area, along with the data needed for their evaluation and scoring. This comprehensive data includes various attributes related to building conditions and maintenance. However, since our primary research objective is to predict the conditions of apartment buildings specifically in the downtown area, we narrowed our focus to the variables most relevant to this goal. To achieve this, we carefully selected key features, like YEAR.BUILT, PROPERTY.TYPE, CONFIRMED.UNITS, CURRENT.BUILDING.EVAL.SCORE, and clean the original dataset, ensuring it aligns with the scope and requirements of our analysis.

## Data Visualization

@fig-data1 illustrates the relationship between CURRENT.BUILDING.EVAL.SCORE and YEAR.BUILT. Each point represents a building, with its year of construction on the x-axis and its evaluation score on the y-axis. The plot includes a trend line generated through linear regression to highlight any general trends. The positive trend line suggests that buildings constructed more recently tend to have slightly higher evaluation scores, although the relationship is not very strong. This could indicate that newer buildings are generally better maintained or constructed to meet higher standards. However, there is considerable variability in the scores for buildings of all ages, as shown by the spread of points around the trend line.

Outliers in the older buildings with high scores could reflect cases where older properties have been well-maintained or renovated. Conversely, some newer buildings with lower scores might indicate specific issues despite their recent construction.

```{r}
#| label: fig-data1
#| tbl-cap: "Relationship between Evaluation Score and Year Built"
#| message: false
#| echo: false
#| warning: false

ggplot(data, aes(x = YEAR.BUILT, y = CURRENT.BUILDING.EVAL.SCORE)) +
  geom_point() +
  geom_smooth(method = "lm", formula = y ~ x, col = "blue") +
  labs(
    x = "Year Built",
    y = "Current Building Evaluation Score"
  )
```

@fig-data2 compares CURRENT.BUILDING.EVAL.SCORE across different PROPERTY.TYPE categories. Each box represents the distribution of scores for a specific property type (e.g., Private, Social Housing, TCHC). The graph shows the median score as well as the range of scores within each category. All property types have relatively high median scores, but slight variations can be observed. TCHC and Social Housing buildings have marginally higher medians than Private properties, suggesting potentially better maintenance or stricter compliance standards. Private properties exhibit the largest range of scores, with several outliers at the lower end. This indicates that some private buildings may significantly underperform in terms of maintenance and compliance. Social Housing and TCHC properties have narrower score distributions, implying more consistent maintenance or management practices. The lower outliers in Private properties highlight a subset of buildings that fall well below the typical evaluation scores, potentially requiring closer attention or intervention.

The graph suggests that Social Housing and TCHC properties are generally more consistent in maintaining standards, while Private properties show greater variability and occasional poor performance.

```{r}
#| label: fig-data2
#| tbl-cap: "Evaluation Score by Property Type"
#| message: false
#| echo: false
#| warning: false

ggplot(data, aes(x = PROPERTY.TYPE, y = CURRENT.BUILDING.EVAL.SCORE)) +
  geom_boxplot() +
  labs(
    x = "Property Type",
    y = "Current Building Evaluation Score"
  )
```

@fig-data3 explores the relationships between building evaluation scores, the number of units, and the number of storeys in Toronto apartment buildings. Graph A illustrates the relationship between the evaluation score and the number of units in a building, while Graph B highlights the relationship between the evaluation score and the number of storeys.

Graph A shows a general trend in the relationship between the number of units and evaluation scores. Buildings with more units tend to have a wide range of scores, suggesting that the number of units alone does not directly predict a building's quality or condition. However, there are clusters of higher scores associated with moderate unit counts, which might indicate a balance between resource allocation and maintenance efforts in mid-sized buildings. The linear regression line provides an overview of the trend, but the scatter suggests considerable variability, indicating other factors may also play significant roles in determining building scores.

Graph B examines the relationship between the number of storeys and building evaluation scores. Buildings with fewer storeys generally display consistent scores, often in the higher range, likely due to simpler maintenance and construction dynamics. Conversely, taller buildings show more variability in scores, with some achieving high evaluations while others fall significantly lower. The regression line suggests a modest trend, but, similar to the first graph, the data points indicate substantial variability within different building heights.

Together, @fig-data3 highlight key patterns in how building size, as measured by units and storeys, relates to evaluation scores. While larger and taller buildings often exhibit more variability in their scores, mid-sized and low-rise buildings show more consistent evaluations. These findings suggest that building design and scale may influence maintenance practices and quality assessments.

```{r}
#| label: fig-data3
#| tbl-cap: "Relationships Between Evaluation Score, Units, and Storeys"
#| message: false
#| echo: false
#| warning: false

# Graph 1: Relationship between Score and Units
plot_units <- ggplot(data, aes(x = CONFIRMED.UNITS, y = CURRENT.BUILDING.EVAL.SCORE)) +
  geom_point(alpha = 0.7, color = "blue") +
  geom_smooth(method = "lm", formula = y ~ x, col = "red") +
  labs(
    title = "A. Evaluation Score and Units",
    x = "Number of Units",
    y = "Evaluation Score"
  ) +
  theme_minimal()

# Graph 2: Relationship between Score and Storeys
plot_storeys <- ggplot(data, aes(x = CONFIRMED.STOREYS, y = CURRENT.BUILDING.EVAL.SCORE)) +
  geom_point(alpha = 0.7, color = "green") +
  geom_smooth(method = "lm", formula = y ~ x, col = "red") +
  labs(
    title = "B. Evaluation Score and Storeys",
    x = "Number of Storeys",
    y = "Evaluation Score"
  ) +
  theme_minimal()

# Combine the two graphs with patchwork
combined_plot <- plot_units + plot_storeys +
  plot_layout(ncol = 2) +
  plot_annotation(
    theme = theme(plot.title = element_text(hjust = 0.5))
  )

# Print the combined plot
combined_plot

```


@fig-data4 shows the distribution of current building evaluation scores across six wards in Toronto, represented by their respective numbers on the x-axis. Each ward corresponds to a specific area: Ward 9 (Davenport), Ward 10 (Spadina-Fort York), Ward 11 (University-Rosedale), Ward 12 (Toronto-St. Paul's), Ward 13 (Toronto Centre), and Ward 14 (Toronto-Danforth). The y-axis represents the evaluation scores, providing insights into the quality or condition of buildings in each ward.

Wards such as Spadina-Fort York (10) and Toronto Centre (13) show relatively higher median scores, suggesting overall better building conditions compared to wards like Davenport (9), which has a slightly lower median score.

Red points below the whiskers indicate buildings with evaluation scores significantly below the rest. For instance, Davenport (9), University-Rosedale (11), and Toronto-St. Paul's (12) exhibit several outliers with very low scores, potentially indicating localized issues with specific buildings in these areas.

Wards like Toronto Centre (13) and Spadina-Fort York (10) exhibit tighter score distributions, suggesting more uniform building quality across the ward. In contrast, wards like Toronto-St. Paul's (12) and University-Rosedale (11) display a wider spread, reflecting greater variability in building conditions.

The majority of the scores for all wards fall between 70 and 90, with exceptions in the form of outliers. This indicates a relatively consistent baseline of building conditions across these areas, though outliers and variability suggest that some buildings deviate significantly from the norm.

```{r}
#| label: fig-data4
#| tbl-cap: "Distribution of Building Evaluation Scores Across Wards"
#| message: false
#| echo: false
#| warning: false

# Generate the graph
ggplot(data, aes(x = factor(WARD), y = CURRENT.BUILDING.EVAL.SCORE)) +
  geom_boxplot(outlier.colour = "red", outlier.shape = 16, outlier.size = 2) +
  geom_jitter(alpha = 0.3, color = "blue", width = 0.2) +
  labs(
    x = "Ward",
    y = "Current Building Evaluation Score"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```


# Model {#sec-model}

In our analysis, we utilized a Bayesian logistic regression model to examine the relationship between apartment evaluation and other building factors ---- built year, number of units, location (ward), and property type. Background details and diagnostics are included in Appendix @sec-model-details.

## Model set-up

The model is formulated as follows:
$$
\begin{aligned}
&\mbox{CURRENT.BUILDING.EVAL.SCORE}_i|\mu_i, \sigma \sim \mbox{Normal}(\mu_i, \sigma) \\
\mu_i &= \beta_0 + \beta_1\mbox{YEAR.BUILT}_i + \beta_2\mbox{PROPERTY.TYPE.CODE}_i + \beta_3\mbox{CONFIRMED.STOREYS}_i \\
& + \beta_4\mbox{CONFIRMED.UNITS}_i + \beta_5\mbox{WARD}_i \\
\beta_{0, 1, ..., 5} &\sim \mbox{Normal}(0, 2.5) \\
\sigma &\sim \mbox{Exponential}(1) \\
\end{aligned}
$$
In this model, $\mbox{CURRENT.BUILDING.EVAL.SCORE}_i$ represents the evaluation score of building $i$. The mean evaluation score, $\mu_i$, is modeled as a linear combination of the intercept $\beta_0$, the effect of the year the building was built $\beta_1 \times \text{YEAR.BUILT}_i$, the effect of the building's property type $\beta_2 \times \text{PROPERTY.TYPE.CODE}_i$, the effect of the number of storeys $\beta_3 \times \text{CONFIRMED.STOREYS}_i$, the effect of the number of units $\beta_4 \times \text{CONFIRMED.UNITS}_i$, and the effect of the ward $\beta_5 \times \text{WARD}_i$. Here, $\text{YEAR.BUILT}_i$ is a continuous predictor, while $\text{PROPERTY.TYPE.CODE}_i$ and $\text{WARD}_i$ are categorical predictors that capture variability due to building type and location, respectively.

The intercept $\beta_0$ represents the baseline evaluation score when all predictors are at their reference or zero levels. The coefficients $\beta_1, \beta_2, \beta_3, \beta_4, \beta_5$ represent the effects of each predictor on the evaluation score. For example, $\beta_1$ captures how the evaluation score changes with each additional year since the building was constructed, while $\beta_3$ quantifies the effect of an additional storey on the score. The categorical variables, $\text{PROPERTY.TYPE.CODE}_i$ and $\text{WARD}_i$, allow the model to account for systematic differences in scores due to property type and location.

Each coefficient $\beta_0, \beta_1, \beta_2, \beta_3, \beta_4, \beta_5$ is assigned a weakly informative prior, $\text{Normal}(0, 2.5)$, which reflects a prior belief that most plausible values for the effects are moderate, but the prior allows for larger effects if supported by the data. This regularization helps prevent overfitting, especially in cases where predictors may be correlated or sample sizes are limited. The residual standard deviation $\sigma$, representing the variability in evaluation scores not explained by the predictors, is modeled using an $\text{Exponential}(1)$ prior, favoring smaller values of variability while still accommodating the possibility of larger residual noise.

This Bayesian framework provides several advantages. It captures the uncertainty in parameter estimates by modeling them probabilistically and allows for regularization through the use of weakly informative priors. By including predictors like $\text{PROPERTY.TYPE.CODE}_i$ and $\text{WARD}_i$, the model accounts for potential heterogeneity in evaluation scores arising from building type and location-specific factors, such as local policies, maintenance practices, or regional infrastructure quality. Compared to traditional frequentist approaches, this Bayesian model ensures robust inference by explicitly modeling uncertainty and leveraging prior information, resulting in more reliable and interpretable results for analyzing building evaluation scores in Toronto.

We run the model in R [@citeR] using the `rstanarm` [@citeRstanarm] package.

## Model justification

Regarding the relationship between building characteristics and evaluation scores, we hypothesize that newer buildings are more likely to receive higher evaluation scores. This assumption is based on the premise that newer buildings typically adhere to updated construction codes, utilize modern materials, and are less affected by wear and tear compared to older buildings. In contrast, older buildings may experience structural or aesthetic degradation over time, leading to lower scores unless significant maintenance or renovation efforts are undertaken.

The number of storeys is expected to positively correlate with evaluation scores. Taller buildings often cater to higher population densities and are generally built to more stringent standards due to the complexities associated with high-rise construction. Furthermore, these buildings may attract greater investment in terms of maintenance and infrastructure to ensure compliance with regulations and to retain their functionality over time.

Similarly, we anticipate that the number of units in a building will positively impact evaluation scores. Larger buildings with more units often benefit from economies of scale, allowing for structured property management systems, dedicated maintenance teams, and better allocation of resources. These factors can contribute to consistent upkeep and adherence to property standards. Conversely, smaller buildings may face resource constraints or lack formal management systems, which could result in lower scores.

The inclusion of property type as a predictor captures differences between building categories, such as private properties, social housing, and TCHC buildings. Each category may face unique challenges and standards based on ownership structure, funding, and operational priorities, which can influence evaluation scores. For example, private buildings may have more financial resources for maintenance, while social housing may face budgetary constraints that impact building conditions.

Finally, the inclusion of ward as a predictor accounts for geographic variability in evaluation scores. Wards represent different neighborhoods in Toronto, each potentially influenced by unique local factors such as socioeconomic conditions, zoning policies, infrastructure quality, and inspection practices. By modeling the effect of wards, the model ensures that unobserved geographic and policy-related factors are captured, improving the robustness of the predictions.

This Bayesian framework was chosen because it allows for the integration of prior knowledge while providing robust uncertainty estimates for each parameter. The weakly informative priors help prevent overfitting, especially when predictors like $\text{PROPERTY.TYPE.CODE}_i$ and $\text{WARD}_i$ introduce categorical variability. By including these key building characteristics and accounting for geographic variability, the model offers a nuanced understanding of how structural and contextual factors influence building evaluation scores.

## Model limitation

While the model provides valuable insights, it has several limitations and relies on assumptions that may not hold in all contexts. First, the assumption of a linear relationship between predictors (e.g., 'YEAR.BUILT' and 'CONFIRMED.UNITS') and the evaluation score may oversimplify complex interactions. For instance, the effect of a building's age on evaluation scores may vary depending on factors like renovation history or maintenance practices, which are not captured in the dataset. Second, the model assumes that the random effect for 'WARD' fully accounts for geographic variability, but unobserved confounders such as neighborhood socioeconomic status or differences in enforcement rigor may influence evaluation outcomes. Additionally, the use of standardized continuous predictors assumes that their scales are comparable, which may obscure meaningful differences in their effects. Finally, the model is context-specific and tailored to Toronto's RentSafeTO program, limiting its generalizability to other regions with different building standards, inspection processes, or housing markets. These limitations suggest the need for cautious interpretation and highlight areas for potential refinement in future analyses.

## Model Validation

For posterior predictive checks, in @fig-post_dist, the alignment of the posterior predictive distribution with the observed building evaluation scores suggests that the model accurately captures the patterns in the data. This indicates the reliability of the model in representing the relationship between building characteristics and evaluation scores. Additionally, @fig-post_prior compares the posterior to the prior distributions, revealing significant parameter shifts, particularly for 'YEAR.BUILT' and 'CONFIRMED.UNITS'. These shifts demonstrate that the data provided strong evidence to update the priors, though minimal changes for some parameters may reflect either limited data informativeness or initial alignment with the priors.

For Markov chain Monte Carlo (MCMC) convergence checks, @fig-trace shows trace plots for the intercept and key predictors. These plots indicate good mixing and consistent exploration of the posterior distribution, suggesting reliable convergence for these parameters. Furthermore, @fig-rhat provides the Gelman-Rubin diagnostic ($\hat{R}$), confirming that all $\hat{R}$ values are below 1.05. This ensures that the chains have converged and the samples are representative of the posterior distribution.

Additional details about the model and validation processes are provided in Appendix @sec-model-details.


# Results {#sec-result}

Our results are summarized in @tbl-modelresults. The findings align well with our expectations regarding the relationships between building characteristics and evaluation scores. To avoid multicollinearity, the model excludes one variable from each category as the reference group: 'WARD' for the ward variable and buildings with fewer than 10 units for the 'CONFIRMED.UNITS' variable. The intercept represents the estimated evaluation score for buildings in 'WARD' with fewer than 10 units, and this baseline score is [Insert Intercept Value Here].

As anticipated, 'YEAR.BUILT' has a positive coefficient, indicating that newer buildings tend to have higher evaluation scores. This suggests that newer buildings, benefiting from modern construction techniques and materials, are generally better maintained or designed to meet higher standards. The positive relationship implies that each additional year of construction is associated with a slight increase in evaluation scores, reflecting the advantages of newer infrastructure.

The number of units in a building ('CONFIRMED.UNITS') also plays a significant role. Buildings with 50–100 units or more than 100 units have higher evaluation scores compared to smaller buildings. The coefficients suggest that larger buildings, likely equipped with better management systems and resources, are better positioned to meet property standards. For instance, buildings with more than 100 units show a larger increase in evaluation scores than those with 50–100 units, further reinforcing the importance of scale in property maintenance.

Geographic location, as captured by 'WARD', exhibits notable variability. Some wards have positive coefficients, indicating higher average evaluation scores compared to the reference ward, while others show negative coefficients, suggesting lower scores. This variability underscores the influence of local factors such as neighborhood policies, inspection practices, or socioeconomic conditions on building evaluations.

@fig-modelresults1 visualizes the 90% credibility intervals for model predictors, offering insights into the certainty of each estimate. Key predictors such as 'YEAR.BUILT', 'CONFIRMED.UNITS', and certain ward effects have credibility intervals that do not overlap zero, indicating strong evidence of their influence on evaluation scores. However, some wards have wider intervals overlapping zero, highlighting uncertainty in their effects.

Together, the results underscore the significant roles of building age, size, and geographic location in determining evaluation scores. These findings suggest that newer, larger buildings in certain wards are better positioned to meet the standards set by the RentSafeTO program. The credibility intervals provide a nuanced understanding of the statistical significance and uncertainty of these predictors.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| label: tbl-modelresults
#| tbl-cap: "Explanatory model Building Evaluation"


#### Load the Model ####
# Load the saved model
bayesian_model <- readRDS("/cloud/project/model/bayesian_model.rds")

#### Generate Summary Table ####
# Create a well-formatted table for the Bayesian model
tab_model(
  bayesian_model,
  show.ci = TRUE,          # Show credible intervals
  show.se = TRUE,          # Show standard errors
  digits = 3,              # Number of digits to round coefficients
  title = "Building Evaluation Score Model",  # Title of the table
  dv.labels = "Evaluation Score"
)

```




# Discussion {#sec-discussion}

##  Achievements {#sec-first-point}

In this paper, we analyzed building evaluation scores from the RentSafeTO dataset to investigate the factors influencing compliance with property standards in Toronto. Using a Bayesian linear regression model, we examined how building characteristics—such as year built, number of units, and geographic location (ward)—affect evaluation scores. Our analysis incorporated random effects to account for ward-level variability and used weakly informative priors to ensure robust inference.

We selected a subset of the dataset focused on downtown Toronto and identified key predictors of building evaluation scores. The results highlight the positive relationships between newer construction, larger building size, and higher evaluation scores, while also revealing variability in scores across different wards. We visualized these relationships using regression plots, boxplots, and credibility interval plots, providing a clear picture of the factors contributing to evaluation outcomes.

Our findings emphasize the importance of building characteristics and local context in determining compliance with property standards. This paper also demonstrates the utility of Bayesian modeling for analyzing hierarchical datasets like RentSafeTO, offering flexibility in capturing both fixed effects and random variability. By focusing on actionable insights, we aim to inform property management practices and policy decisions aimed at improving housing standards in Toronto.

## About Building Maintenance and Standards {#sec-second-point}

From this analysis, we gain valuable insights into the factors that influence building maintenance and compliance with property standards. Specifically, we learn that newer buildings tend to perform better in evaluations, suggesting that modern construction practices and adherence to updated regulations play a significant role in meeting maintenance standards. This highlights the importance of updating building codes and encouraging renovations to improve compliance in older properties.

Additionally, the positive relationship between the number of units in a building and its evaluation score underscores the role of scale in property management. Larger buildings, often equipped with more structured management systems and dedicated resources, appear better positioned to meet maintenance standards compared to smaller properties. This finding suggests that economies of scale in management can lead to better overall building conditions.

Lastly, the variability in scores across different wards reveals how geographic and neighborhood factors influence compliance. Local policies, enforcement rigor, and neighborhood socioeconomic conditions likely contribute to these differences, underscoring the need for context-sensitive strategies to improve housing standards across the city.

## Limitation {#sec-third-point}

There are several limitations to consider. First, the RentSafeTO dataset only includes buildings registered under the program, excluding smaller buildings and those not covered by the bylaw. As a result, the findings may not generalize to all rental housing in Toronto, particularly for properties outside the program’s scope.

Additionally, the dataset primarily focuses on physical and structural conditions, leaving out important contextual factors such as tenant satisfaction, management practices, or broader social influences on building quality. These unobserved variables may introduce bias or limit the comprehensiveness of the analysis. Moreover, evaluation scores rely on inspections conducted by different bylaw enforcement officers, which may lead to variability due to subjective judgment or inconsistencies in enforcement practices.

The Bayesian model employed in this analysis assumes linear relationships between predictors, such as YEAR.BUILT and CONFIRMED.UNITS, and evaluation scores. While this simplification is useful for interpretability, it may overlook more complex interactions, such as the combined effects of building age and maintenance practices. Furthermore, missing values in key variables, such as evaluation scores and building characteristics, pose challenges for analysis. For instance, blank or zero scores may reflect non-evaluated cases rather than true building conditions, potentially skewing the results.

Finally, the results are context-specific and tailored to the RentSafeTO program in Toronto. They may not apply to other regions with different building standards, enforcement practices, or housing markets. These limitations emphasize the need for cautious interpretation of the findings and highlight areas for future research, such as integrating qualitative data on tenant experiences or examining the impact of inspector variability on evaluation outcomes.

## Next steps {#sec-fourth-point}

First, expanding the dataset to include a broader range of buildings, including smaller rental properties and those not registered with RentSafeTO, would provide a more comprehensive understanding of building conditions across Toronto. Incorporating data from other regions could also help generalize the findings and explore how different enforcement practices or housing markets affect evaluation outcomes.

Second, integrating additional variables, such as tenant satisfaction surveys, management practices, and neighborhood socioeconomic factors, would provide a more holistic view of what influences building quality. This could help identify factors beyond physical structure that contribute to compliance with property standards. Collecting longitudinal data on building conditions over time could also help explore the effects of renovations, policy changes, or aging on evaluation scores.

Third, standardizing inspection practices and incorporating measures to assess variability between inspectors could improve the reliability of evaluation scores. Training programs and inter-rater reliability checks could be implemented to ensure consistency in scoring across different inspectors and regions.

Finally, applying more flexible modeling approaches could capture complex interactions between predictors. For example, hierarchical or non-linear models might better reflect how building age, size, and geographic factors interact to influence evaluation scores. Exploring machine learning approaches could also help uncover hidden patterns in the data while providing robust predictions.




\newpage

\appendix

# Appendix {-}

# Data details {#sec-data-details}

## Raw data

@tbl-raw shows the preview of the raw RentSafeTo dataset.

```{r}
#| label: tbl-raw
#| tbl-cap: "Preview of the raw RentSafeTo dataset"
#| message: false
#| echo: false
#| warning: false

raw_data <- read.csv("/cloud/project/data/01-raw_data/raw_apt_data.csv")

print(head(raw_data[, 1:10], 5), width = 100)
```

## Selected variables

We choose several variables for our report. The "RSN" (Record Serial Number) is the ID number for a building in RentSafeTO Open Data Sets.The "WARD" variable indicates the location where the building is located, represented numerically. Wards are geographical divisions within the city, and their names are specified in the "WARDNAME" variable. The "YEAR.BUILT" variable records the year the building was constructed. The "PROPERTY.TYPE" variable describes the type of property ownership (private, social housing, and TCHC). "CONFIRMED.STOREYS" denotes the number of floors in the building, while "CONFIRMED.UNITS" represents the total number of housing units in the building.

Finally, the "CURRENT.BUILDING.EVAL.SCORE" is an assessment of the building's compliance with property standards. This score is derived by combining reactive scores (responses to complaints or issues) and proactive scores (regular inspections or maintenance reports). It serves as a comprehensive measure of the building's condition and adherence to local property regulations.

Particularly, 'WARD' is the number from the 25-ward system (@ward) which is used to mark different regions in Toronto. In this report, we choose 9, 10, 11, 12, 13, and 14, which are 'Davenport', 'Spadina-Fort York', 'University-Rosedale', 'Toronto-St. Paul's', 'Toronto Centre', and 'Toronto-Danforth'.

# Model details {#sec-model-details}

## Posterior predictive check

```{r}
#| label: fig-post_dist
#| fig-cap: Posterior predictive distribution for Bayesian linear model
#| echo: false
#| warning: false
#| message: false

# Load the saved model
bayesian_model <- readRDS("/cloud/project/model/bayesian_model.rds")

# Perform posterior predictive checks
pp_check(bayesian_model, type = "dens_overlay") +
  theme_minimal() +
  theme(legend.position = "bottom") +
  ggtitle("Posterior Predictive Check: Density Overlay")
```

```{r}
#| label: fig-post_prior
#| fig-cap: Comparison of posterior and prior distributions for Bayesian linear model
#| echo: false
#| warning: false
#| message: false

prior_draws <- tibble(
  `(Intercept)` = rnorm(4000, 0, 5),
  `YEAR.BUILT` = rnorm(4000, 0, 2.5),
  `CONFIRMED.UNITS` = rnorm(4000, 0, 2.5)
) %>%
  pivot_longer(cols = everything(), names_to = "Parameter", values_to = "Value") %>%
  mutate(Type = "Prior")

# Extract posterior samples
posterior_draws <- as_draws_df(as.matrix(bayesian_model)) %>%
  select(`(Intercept)`, `YEAR.BUILT`, `CONFIRMED.UNITS`) %>%
  pivot_longer(cols = everything(), names_to = "Parameter", values_to = "Value") %>%
  mutate(Type = "Posterior")

# Combine prior and posterior samples
prior_posterior <- bind_rows(prior_draws, posterior_draws)

# Plot comparison of posterior and prior
ggplot(prior_posterior, aes(x = Parameter, y = Value, color = Type, fill = Type)) +
  stat_halfeye(alpha = 0.6, adjust = 0.5, width = 0.7, justification = -0.3) +
  theme_minimal() +
  coord_flip() +
  labs(
    title = "Comparison of Posterior and Prior Distributions",
    x = "Parameter",
    y = "Value",
    color = "Distribution Type",
    fill = "Distribution Type"
  ) +
  theme(
    legend.position = "bottom",
    axis.text.x = element_text(hjust = 1, vjust = 0.5),
    text = element_text(size = 8)
  ) +
  guides(color = guide_legend(ncol = 4))
```

In @fig-post_dist, we compare the model's predicted values to the observed data. This involves overlaying the posterior predictive distribution on the observed data distribution. The purpose of this check is to evaluate whether the model can reproduce patterns and variability seen in the actual evaluation scores. The results indicate a good fit, as the predicted and observed distributions align closely, suggesting the model captures the underlying structure of the data effectively. This validation supports the model's reliability in representing the relationship between building characteristics and evaluation scores.

@fig-post_prior compares the posterior with the prior distributions for key parameters in the Bayesian model, including the intercept, 'YEAR.BUILT', and 'CONFIRMED.UNITS'. The plot uses overlapping density curves to illustrate how the data influenced the parameter estimates. The posterior distributions shift away from the priors, indicating that the data provided substantial evidence to update the parameter values. For instance, the posterior for 'YEAR.BUILT' narrows and centers around values informed by the observed data, reflecting its significant role in predicting evaluation scores.

## Markov chain Monte Carlo Convergence Check

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-trace
#| fig-cap: "Trace plot of intercept and predictors"
#| fig-subcap: ["Trace plot of Intercept", "Trace plot of YEAR.BUILT", "Trace plot of CONFIRMED.UNITS"]
#| layout-ncol: 2

# Load the saved model
bayesian_model <- readRDS("/cloud/project/model/bayesian_model.rds")

# Trace plots for key fixed effects
plot(bayesian_model, "trace", "(Intercept)")
plot(bayesian_model, "trace", "YEAR.BUILT")
plot(bayesian_model, "trace", "CONFIRMED.UNITS")
```

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-rhat
#| fig-cap: "Rhat plot"

plot(bayesian_model, "rhat")
```


# 90% Credibility Interval {#sec-credibility-interval}

@fig-modelresults is a 90% credibility interval plot.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| label: fig-modelresults
#| fig-cap: "90% Credibility Intervals for Building Evaluation Model Predictors"

# Load the saved model
bayesian_model <- readRDS("/cloud/project/model/bayesian_model.rds")

# Generate 90% credibility interval plot
modelplot(bayesian_model, conf_level = 0.90, size = 0.2) +
  labs(
    x = "90% Credibility Interval",
    title = "Credible Intervals for Building Evaluation Model Predictors"
  ) +
  theme(
    axis.text.y = element_text(size = 6),
    axis.title.y = element_blank() # Remove y-axis title for a cleaner look
  )

```


@fig-trace is a trace plot. It shows the sampling paths for key fixed effects, including the intercept, 'YEAR.BUILT', and 'CONFIRMED.UNITS', across all Markov chains. The plots demonstrate good mixing, with chains overlapping and exploring the posterior distribution consistently without any visible drifts or irregular patterns. This suggests that the sampling process converged for these parameters, providing reliable estimates for the posterior distributions.

@fig-rhat is a Rhat plot. It shows the Gelman-Rubin diagnostic $\hat{R}$ for all model parameters, which assesses convergence across Markov chains. All $\hat{R}$ values are close to 1 and below the commonly accepted threshold of 1.05, indicating that the chains have converged, and the samples are representative of the posterior distribution. This suggests that the model has achieved satisfactory convergence, and the parameter estimates can be trusted for inference.


# Survey {#sec-survey}

## Overview

The goal of this survey is to gather residents' opinions about the condition and maintenance of their apartment buildings, complementing the RentSafeTO evaluation system. By incorporating tenant perspectives, the survey aims to provide a holistic understanding of building quality and identify areas for improvement. This feedback will help property managers, policymakers, and enforcement agencies address tenant concerns, prioritize maintenance efforts, and enhance housing standards across Toronto.

The survey focuses on key aspects of apartment living, including cleanliness, safety, maintenance responsiveness, and overall satisfaction. The collected data will be analyzed alongside the RentSafeTO evaluation scores to explore correlations between tenant perceptions and objective building assessments.

## Sampling Approach

Target Population: 
The target population includes residents of multi-unit residential buildings registered under the RentSafeTO program in Toronto. This ensures alignment with the buildings already evaluated by the program.

Sample Size: 
To ensure representativeness, the survey will aim to collect responses from approximately 5,000 residents, distributed proportionally across all wards in Toronto. The sample size is calculated to provide reliable insights with a margin of error of ±3% at a 95% confidence level.

Sampling Technique: 
A stratified random sampling approach will be used:
Strata: The sampling will be stratified by ward to ensure geographic diversity.
Random Sampling: Within each ward, a random sample of buildings will be selected, and a set number of residents per building will be invited to participate.

Geographic Coverage:
The survey will cover all 25 wards in Toronto, ensuring equitable representation of diverse neighborhoods and building types. Special attention will be given to include a mix of private, social housing, and Toronto Community Housing Corporation (TCHC) properties.

## Recruitment of Respondents

Outreach Channels:
Email Invitations: Contact information will be obtained from property managers, with consent, to send email invitations to residents.
Posters and Flyers: Informational posters and flyers will be placed in common areas of selected buildings.
Community Partnerships: Collaboration with local tenant associations and housing organizations to encourage participation.

Incentives:
To boost response rates, participants will be offered a chance to win one of 50 $25 gift cards through a random draw. The incentive will be clearly communicated during recruitment.

Ensuring Anonymity:
To encourage honest responses, the survey will be anonymous, with no identifying information collected. This will be emphasized in all recruitment materials.

## Survey Design

Survey Format
The survey will be conducted online using Google Forms, with an option for paper forms for residents without internet access. It will take approximately 10 minutes to complete.

Sections and Question Types
Demographics:

Age group (checkboxes)
Tenure in the building (dropdown menu: less than 1 year, 1–5 years, more than 5 years)
Housing type (radio buttons: private, social housing, TCHC)
Building Condition:

"How would you rate the cleanliness of your building?" (Likert scale: 1–5)
"Are common areas, such as hallways and lobbies, well-maintained?" (Yes/No)
Safety and Security:

"Do you feel safe in your building?" (Likert scale: 1–5)
"Are security measures, such as cameras or locks, adequate?" (Yes/No)
Maintenance and Responsiveness:

"How satisfied are you with the responsiveness of building management to maintenance requests?" (Likert scale: 1–5)
"How long does it typically take for maintenance requests to be resolved?" (multiple choice: less than a week, 1–2 weeks, more than 2 weeks)
Overall Satisfaction:

"How satisfied are you overall with living in your building?" (Likert scale: 1–5)
"What is the most pressing issue you face as a tenant?" (open-ended)
Suggestions for Improvement:

"What changes would improve your living experience?" (open-ended)
Pilot Testing
The survey will be pilot-tested with 50 respondents to ensure clarity and effectiveness. Feedback will be incorporated to refine the questions and structure.

### Link

https://docs.google.com/forms/d/e/1FAIpQLSdN_4gdZUWW0m9YNXgFPflU_DjmRexdUMZNHmX1INj0s2c_2g/viewform?usp=sf_link



# References
